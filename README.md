# Protea

Self-evolving artificial life system. The program is a living organism â€” it can self-restructure, self-reproduce, and self-evolve.

## Architecture

Three-ring design running on a single Mac mini:

- **Ring 0 (Sentinel)** â€” Immutable physics layer. Supervises Ring 2, performs heartbeat monitoring, git snapshots, rollback on failure, fitness tracking, and persistent storage (SQLite). Pure Python stdlib.
- **Ring 1 (Intelligence)** â€” LLM-driven evolution engine, task executor, Telegram/Matrix bots, skill crystallizer, dashboard. Supports multiple LLM providers (Anthropic, OpenAI, DeepSeek, Qwen).
- **Ring 2 (Evolvable Code)** â€” The living code that evolves each generation. Managed by Ring 0.

## Prerequisites

- Python 3.11+
- Git

## Quick Start

```bash
# Remote install (clones repo, creates venv, configures .env, runs tests)
curl -sSL https://raw.githubusercontent.com/Drlucaslu/protea/main/setup.sh | bash
cd protea && .venv/bin/python run.py
```

Or manually:

```bash
git clone https://github.com/Drlucaslu/protea.git && cd protea
bash setup.sh
.venv/bin/python run.py
```

For background operation with automatic watchdog restart:

```bash
bash run_with_nohup.sh
```

## Project Structure

```
protea/
â”œâ”€â”€ ring0/                      # Ring 0 â€” Sentinel (pure stdlib)
â”‚   â”œâ”€â”€ sentinel.py             # Main supervisor loop
â”‚   â”œâ”€â”€ heartbeat.py            # Ring 2 heartbeat monitoring
â”‚   â”œâ”€â”€ git_manager.py          # Git snapshot + rollback
â”‚   â”œâ”€â”€ fitness.py              # Fitness scoring + plateau detection
â”‚   â”œâ”€â”€ memory.py               # Tiered memory store (hot/warm/cold) + vector search
â”‚   â”œâ”€â”€ skill_store.py          # Crystallized skill store
â”‚   â”œâ”€â”€ gene_pool.py            # Gene pool â€” evolutionary inheritance
â”‚   â”œâ”€â”€ task_store.py           # Task persistence store
â”‚   â”œâ”€â”€ scheduled_task_store.py # Cron / one-shot scheduled tasks
â”‚   â”œâ”€â”€ output_queue.py         # Evolution output queue â€” user feedback loop
â”‚   â”œâ”€â”€ user_profile.py         # User profiling â€” topic extraction + interest decay
â”‚   â”œâ”€â”€ preference_store.py     # Structured preference store
â”‚   â”œâ”€â”€ evolution_intent.py     # Intent classification + blast radius
â”‚   â”œâ”€â”€ commit_watcher.py       # Auto-restart on new commits
â”‚   â”œâ”€â”€ cron.py                 # Cron expression parser
â”‚   â”œâ”€â”€ resource_monitor.py     # CPU/memory/disk monitoring
â”‚   â””â”€â”€ sqlite_store.py         # Base SQLite store mixin
â”‚
â”œâ”€â”€ ring1/                      # Ring 1 â€” Intelligence layer
â”‚   â”œâ”€â”€ evolver.py              # LLM-driven code evolution + blast radius gate
â”‚   â”œâ”€â”€ prompts.py              # Evolution + crystallization prompts
â”‚   â”œâ”€â”€ crystallizer.py         # Skill crystallization from surviving code
â”‚   â”œâ”€â”€ auto_crystallizer.py    # Automatic crystallization triggers
â”‚   â”œâ”€â”€ llm_base.py             # LLM client ABC + factory + thread-safe timeout
â”‚   â”œâ”€â”€ llm_client.py           # Anthropic Claude client
â”‚   â”œâ”€â”€ llm_openai.py           # OpenAI / DeepSeek / Qwen client
â”‚   â”œâ”€â”€ task_executor.py        # P0 user tasks + P1 autonomous tasks
â”‚   â”œâ”€â”€ task_generator.py       # Autonomous task generation
â”‚   â”œâ”€â”€ preference_extractor.py # Implicit preference signal extraction
â”‚   â”œâ”€â”€ habit_detector.py       # User habit pattern detection
â”‚   â”œâ”€â”€ proactive_loop.py       # Proactive suggestion engine
â”‚   â”œâ”€â”€ directive_generator.py  # Dynamic evolution direction
â”‚   â”œâ”€â”€ convergence_detector.py # Evolution convergence detection
â”‚   â”œâ”€â”€ memory_curator.py       # LLM-assisted memory curation
â”‚   â”œâ”€â”€ embeddings.py           # Embedding provider (OpenAI / local hash)
â”‚   â”œâ”€â”€ telegram_bot.py         # Telegram bot (commands + free-text)
â”‚   â”œâ”€â”€ telegram.py             # Telegram notifier (one-way)
â”‚   â”œâ”€â”€ matrix_bot.py           # Matrix bot via Client-Server API
â”‚   â”œâ”€â”€ dashboard.py            # Web dashboard (memory, skills, profile, intent)
â”‚   â”œâ”€â”€ skill_portal.py         # Skill web UI
â”‚   â”œâ”€â”€ skill_runner.py         # Skill process manager
â”‚   â”œâ”€â”€ skill_sandbox.py        # Skill venv + dependency manager
â”‚   â”œâ”€â”€ task_sync.py            # Task template â†” hub sync
â”‚   â”œâ”€â”€ skill_validator.py      # Skill code validation
â”‚   â”œâ”€â”€ registry_client.py      # Hub registry client (task templates)
â”‚   â”œâ”€â”€ subagent.py             # Background task subagents
â”‚   â”œâ”€â”€ tool_registry.py        # Tool dispatch framework
â”‚   â”œâ”€â”€ tools/                  # Tool implementations
â”‚   â”‚   â”œâ”€â”€ filesystem.py       # read_file, write_file, edit_file, list_dir
â”‚   â”‚   â”œâ”€â”€ shell.py            # exec (sandboxed shell)
â”‚   â”‚   â”œâ”€â”€ web.py              # web_search, web_fetch
â”‚   â”‚   â”œâ”€â”€ message.py          # Progress messages to user
â”‚   â”‚   â”œâ”€â”€ skill.py            # run_skill, view_skill, edit_skill
â”‚   â”‚   â”œâ”€â”€ spawn.py            # Background task spawning
â”‚   â”‚   â”œâ”€â”€ schedule.py         # Scheduled task management
â”‚   â”‚   â”œâ”€â”€ send_file.py        # File sending to chat
â”‚   â”‚   â”œâ”€â”€ report.py           # Report generation
â”‚   â”‚   â””â”€â”€ progress_monitor.py # Task progress monitoring
â”‚   â”œâ”€â”€ web_tools.py            # DuckDuckGo + URL fetch
â”‚   â””â”€â”€ pdf_utils.py            # PDF text extraction
â”‚
â”œâ”€â”€ ring2/                      # Ring 2 â€” Evolvable code
â”‚   â””â”€â”€ main.py                 # The living program (auto-evolved, never commit manually)
â”‚
â”œâ”€â”€ config/config.toml          # Configuration
â”œâ”€â”€ data/                       # SQLite databases (auto-created)
â”œâ”€â”€ tests/                      # 1900+ tests
â”œâ”€â”€ run.py                      # Entry point
â”œâ”€â”€ run_with_nohup.sh           # Background launcher with watchdog
â””â”€â”€ setup.sh                    # One-step installer
```

## How It Works

1. **Sentinel** starts Ring 2 as a subprocess
2. Ring 2 writes a `.heartbeat` file every 2s; Sentinel checks freshness
3. If Ring 2 **survives** `max_runtime_sec`: score fitness, crystallize skills, evolve code, advance generation
4. If Ring 2 **dies**: rollback to last good commit, evolve from rollback base, restart
5. Each generation gets deterministic parameters from a seeded PRNG
6. **CommitWatcher** detects new git commits and triggers `os.execv()` restart
7. **TaskStore** persists queued tasks to SQLite â€” they survive restarts

## Evolution & Fitness

Fitness is scored 0.0â€“1.0 with six components:

| Component | Weight | Description |
|-----------|--------|-------------|
| Base survival | 0.50 | Survived max_runtime_sec |
| Output volume | 0.10 | Meaningful non-empty lines (saturates at 50) |
| Output diversity | 0.10 | Unique lines / total lines |
| Novelty | 0.05 | Jaccard distance vs recent generations' output |
| Structured output | 0.10 | JSON, tables, key:value patterns |
| Functional bonus | 0.05 | Real I/O, HTTP, file operations detected |
| Error penalty | âˆ’0.10 | Traceback/error/exception lines |

### Incremental Evolution

Evolution prefers **incremental modification** over full rewrites. A blast radius gate in the evolver rejects full rewrites (>70% lines changed) when the code is working fine (`optimize` intent). Larger changes are allowed when the code is broken (`repair`), stagnant (`explore`), or a user directive is pending (`adapt`).

### Evolution Intent

Each evolution is classified by intent (priority order):

1. **adapt** â€” User directive pending (highest priority)
2. **repair** â€” Code crashed or has persistent errors
3. **explore** â€” Scores plateaued
4. **optimize** â€” Code survived, make incremental improvements

When scores plateau and no directive is pending, LLM evolution calls are **skipped** to save tokens.

## Closed-Loop Evolution Feedback

After evolution survives, new capabilities are detected (via AST diff) and pushed to the user through Telegram with inline buttons:

| Button | Effect |
|--------|--------|
| ðŸ‘ ä¸é”™ | Boost gene fitness; mark as "accepted" â€” future evolution preserves this direction |
| ðŸ“Œ å®šæœŸæ‰§è¡Œ | Create a scheduled task from the capability; boost gene fitness |
| ðŸ‘Ž ä¸è¦äº† | Delete the gene; mark as "rejected" â€” future evolution avoids this direction |
| *(silence)* | Auto-expire after 24h; mild decay |

Accepted and rejected capabilities are injected into the evolution prompt as constraints, so the LLM doesn't re-evolve solved problems or pursue unwanted directions. Rate-limited to 5 pushes/day.

## Gene Pool

Evolved code patterns are preserved across generations via a local **gene pool**. When Ring 2 survives, its source code is analysed (AST) to extract a compact gene summary (~200â€“500 tokens). The top 100 genes (by fitness score) are stored in SQLite.

During evolution, the best 2â€“3 gene summaries are injected into the LLM prompt as **Inherited Patterns**. During task execution, genes are filtered by a **semantic relevance threshold** (`min_semantic=1.0`) to avoid injecting unrelated patterns.

## Multi-LLM Provider Support

| Provider | Config | Default Model |
|----------|--------|---------------|
| Anthropic (default) | `CLAUDE_API_KEY` env var | claude-sonnet-4-5 |
| OpenAI | `[ring1.llm]` section | gpt-4o |
| DeepSeek | `[ring1.llm]` section | deepseek-chat |
| Qwen (åƒé—®) | `[ring1.llm]` section | qwen3.5-plus |

```toml
[ring1.llm]
provider = "qwen"
api_key_env = "DASHSCOPE_API_KEY"
model = "qwen3.5-plus"
max_tokens = 8192
```

Each HTTP request runs in a daemon thread with a 90-second hard timeout to guard against socket hangs.

## Long-Term Memory

Three-tier memory system with importance scoring and selective forgetting:

| Tier | Retention | Description |
|------|-----------|-------------|
| Hot | Recent 10 generations | Active memories, full fidelity |
| Warm | 10â€“30 generations | Compacted by type, top-3 per group kept |
| Cold | 30â€“100 generations | LLM-curated (keep / summarize / discard) |
| Forgotten | >100 generations | Deleted if importance < 0.3 |

Optional **semantic search**: when an embedding provider is configured, memories are stored with 256-dim vectors. Retrieval uses hybrid scoring (0.4 keyword + 0.6 cosine similarity).

## Dashboard

Local web UI at `http://localhost:8899`:

| Page | Content |
|------|---------|
| Overview | Stat cards + SVG fitness chart |
| Memory | Browsable table with tier/type filters |
| Skills | Card grid with usage counts and tags |
| Templates | Published and discoverable task templates |
| Intent | Vertical timeline of evolution intents |
| Profile | Category bar chart + interaction stats |

All pages have JSON API counterparts (`/api/memory`, `/api/skills`, etc.).

## Telegram Commands

| Command | Description |
|---------|-------------|
| `/status` | Status panel (generation, uptime, executor health) |
| `/history` | Recent 10 generations |
| `/top` | Top 5 fitness scores |
| `/code` | View current Ring 2 source |
| `/pause` / `/resume` | Pause/resume evolution |
| `/kill` | Restart Ring 2 |
| `/direct <text>` | Set evolution directive |
| `/tasks` | Task queue + recent history |
| `/memory` | Recent memories |
| `/forget` | Clear all memories |
| `/skills` | List crystallized skills |
| `/skill <name>` | View skill details |
| `/run <name>` | Start a skill process |
| `/stop` | Stop running skill |
| `/running` | Running skill status |
| `/background` | Background subagent tasks |
| `/files` | List uploaded files |
| `/find <prefix>` | Search files by name |
| *free text* | Submit as P0 task to LLM |

## Configuration

All settings in `config/config.toml`:

- **ring0**: heartbeat intervals, resource limits, evolution seed/cooldown, plateau detection, skill cap
- **ring1**: `CLAUDE_API_KEY`, `TELEGRAM_BOT_TOKEN`, `TELEGRAM_CHAT_ID` (env vars)
- **ring1.llm**: multi-provider LLM config (provider, model, api_key_env, api_url)
- **ring1.dashboard**: local dashboard (enabled, host, port)
- **ring1.embeddings**: vector search (provider, model, dimensions)

## Task Template Sharing

Scheduled tasks that prove their value (run_count >= 2) are automatically shared as **task templates** via [protea-hub](https://github.com/lianglu/protea-hub). Each template is a parameterized intent+trigger+execution triple in natural language. Other Protea instances can discover and install relevant templates based on their user profile.
